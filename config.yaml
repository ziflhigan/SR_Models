model:
  name: "srgan"  # Options: "srcnn" or "srgan"
  device: "cuda"  # Options: "cuda" or "cpu"

# Dataset Configuration
dataset:
  name: "DIV2K"
  scale_factor: 4  # Upscaling factor: 2, 3, 4, 8
  train_hr_dir: "DIV2K/DIV2K_train_HR"
  train_lr_dir: "DIV2K/DIV2K_train_LR_bicubic/X4"
  valid_hr_dir: "DIV2K/DIV2K_valid_HR"
  valid_lr_dir: "DIV2K/DIV2K_valid_LR_bicubic/X4"

  # Data preprocessing
  hr_crop_size: 96  # Size of HR patches for training
  augmentation:
    horizontal_flip: true
    vertical_flip: true
    rotation: true  # 90-degree rotations

  # Normalization
  normalize: true
  norm_type: "minus_one_one"  # Options: "zero_one" [0,1] or "minus_one_one" [-1,1]

# Training Configuration
training:
  epochs: 100
  batch_size: 16
  num_workers: 4  # DataLoader workers
  reproducible: false # Set to true for strict reproducibility

  # Learning rate settings
  learning_rate:
    generator: 0.0001  # For SRGAN generator or SRCNN
    discriminator: 0.00001  # For SRGAN discriminator only

  # Learning rate scheduler
  scheduler:
    enabled: true
    type: "two_stage"  # Options: "step", "cosine", "plateau"

    # Step scheduler
    step_size: 50
    gamma: 0.5

    # two_stage scheduler
    milestone: 25  # Epoch at which to decay the learning rate
    decay_factor: 0.1 # Factor to multiply LR by (e.g., 1e-4 -> 1e-5 means 0.1)

  # Checkpointing
  checkpoint:
    save_interval: 10  # Save every N epochs
    save_best: true  # Save best model based on validation metric
    metric: "psnr"  # Metric to monitor for best model

  # Early stopping
  early_stopping:
    enabled: true
    patience: 10
    min_delta: 0.001

  # Mixed precision training
  use_amp: true  # Automatic mixed precision

# SRCNN-specific Configuration
srcnn:
  # Network architecture
  num_channels: 3  # Input/output channels (3 for RGB)
  f1: 64  # Number of filters in first layer
  f2: 32  # Number of filters in second layer
  kernel_sizes: [9, 1, 5]  # Kernel sizes for each layer

  # Loss function
  loss_type: "mse"  # Options: "mse" or "l1"

  init_type: "kaiming" # Options: "kaiming" or "normal"
  padding_mode: "same"  # Options: "same" or "valid"

# SRGAN-specific Configuration
srgan:
  # Generator architecture
  generator:
    num_channels: 3
    num_features: 64
    num_blocks: 16  # Number of residual blocks
    use_batch_norm: false

  # Discriminator architecture
  discriminator:
    num_channels: 3
    num_features: 64

  # Loss configuration
  loss:
    content_loss: "vgg"  # Options: "mse", "l1", or "vgg"
    vgg_layer: "relu5_4"  # VGG feature layer for perceptual loss
    content_weight: 1.0
    adversarial_weight: 0.001

    # for discriminator regularization
    label_smoothing:
      enabled: false
      factor: 0.1 # Use labels [0.9, 1.0] for real and [0.0, 0.1] for fake

  # Training strategy
  pretrain:
    enabled: true
    epochs: 50              # Number of epochs for pre-training only
    validation_interval: 10  # How often to validate during pre-training
    checkpoint_interval: 10  # How often to save checkpoints during pre-training

 # for GAN training balance
  training_ratio:
    enabled: true
    generator_steps: 1      # Number of updates for G
    discriminator_steps: 2  # Number of updates for D

# Validation Configuration
validation:
  interval: 1  # Validate every N epochs
  save_images: true  # Save sample images during validation
  num_samples: 5  # Number of sample images to save

# Logging Configuration
logging:
  level: "INFO"  # Options: "DEBUG", "INFO", "WARNING", "ERROR"
  console: true  # Log to console
  file: true  # Log to file

# Output Directories
output:
  checkpoint_dir: "checkpoints"
  log_dir: "logs"
  result_dir: "results"

# Metrics to track
metrics:
  - "psnr"
  - "ssim"
  - "loss"

visualization:
  enabled: true
  style: "seaborn-v0_8-darkgrid" # Style for plots (e.g., "ggplot", "seaborn-v0_8-whitegrid")
  save_interim_plots: true     # Save plots whenever a new best model is found
  image_format: "png"          # Format for saved plots ("png", "svg", "pdf")